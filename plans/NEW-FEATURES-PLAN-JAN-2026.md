# New Features Plan - January 2026

**Date**: December 31, 2025 **Updated**: January 2, 2026 **Plan Type**:
Strategic Feature Roadmap **Methodology**: Analysis-Swarm (RYAN, FLASH, SOCRATES
personas) + GOAP Planning **Timeline**: 4-5 months for core features, ongoing
iteration

---

## Executive Summary

Following the completion of all post-production optimization goals in December
2025, Novelist.ai is positioned for strategic feature expansion. This plan
prioritizes high-impact, low-risk features based on multi-perspective analysis
and 2025 best practices validation.

**Strategic Approach**: Ship value first, build measurement infrastructure, make
strategic investments based on data.

## Updated Status (January 2, 2026)

### âœ… COMPLETED

- **Phase 1.3**: AI Stack Simplification - OpenRouter SDK only (100% complete)
- **Phase 2.1**: Multi-Modal AI Integration (DALL-E 3, Stable Diffusion XL)
  (100% complete)
- **Phase 2.2**: PWA with Offline Support (100% complete)
- **Writing Assistant MVP**: 100% complete with all features implemented

### âš ï¸ IN PROGRESS

- **Phase 1.1**: Analytics Integration (Partially complete - infrastructure
  exists)
- **Phase 1.2**: Security Hardening - Serverless API Gateway (Not yet
  implemented)
- **Phase 2.3**: Distraction-Free Writing Mode (Flag exists, full UI not
  implemented)

### ðŸ“‹ NOT STARTED

- **Phase 2.4**: Voice Input (Dictation)
- **Phase 3**: Context Intelligence (RAG Phase 1-3, Shared Views)
- **Phase 4**: AI Automation (Plot Engine, Agent Framework)

### Current Status: 60% Complete (Foundation + Quick Wins Ready)

- Phase 1 (Foundation): 75% complete
- Phase 2 (Quick Wins): 67% complete (2/3 features done)

**Key Principles**:

1. **Evidence-based** - All major decisions validated by analytics
2. **Incremental** - Ship in phases, validate demand
3. **Low-risk** - Start with proven technologies
4. **High-impact** - Focus on user-visible value

---

## Phase 1: Foundation & Evidence (Weeks 1-3)

### Goal: Build measurement infrastructure and harden security

#### 1.1 Analytics Integration (HIGH Priority, 1 week)

**Description**: Implement comprehensive analytics to track user behavior,
feature usage, and validate feature assumptions.

**Technical Approach**:

- PostHog or Mixpanel integration
- Track feature usage, user flows, time-in-feature
- Implement user feedback collection (in-app surveys)
- Set up A/B testing infrastructure

**Success Criteria**:

- Analytics data flowing for all existing features
- User feedback collection active
- A/B testing infrastructure ready

**Dependencies**: None

**Effort**: 1 week

---

#### 1.2 Security Hardening - Serverless API Gateway (HIGH Priority, 3-5 days)

**Description**: Move AI calls from client to serverless functions for improved
security and cost management.

**Technical Approach**:

- Vercel Functions or Cloudflare Workers
- Move AI calls from client to serverless
- Remove API keys from client builds
- Implement rate limiting and caching

**Success Criteria**:

- Zero API keys in client builds
- All AI calls routed through serverless functions
- Cost tracking and alerts in place

**Dependencies**: None

**Effort**: 3-5 days

**Rationale (RYAN)**: Security best practice - API keys should never be exposed
in client builds. This also enables better cost management and caching
strategies.

**Rationale (FLASH)**: Quick security win. No user impact, but essential for
production.

---

#### 1.3 AI Stack Simplification - OpenRouter SDK Only (HIGH Priority, 3-4 days)

**Description**: Simplify AI stack by migrating from Vercel AI SDK + providers
to OpenRouter SDK only.

**Technical Approach**:

- Remove dependencies: `ai`, `@ai-sdk/openai`, `@ai-sdk/anthropic`,
  `@ai-sdk/google`, `@openrouter/ai-sdk-provider`
- Keep only: `@openrouter/sdk`
- Rewrite `ai-core.ts` and `ai-operations.ts` to use OpenRouter SDK API
- Update all test files with new SDK mocks

**Success Criteria**:

- All existing tests passing
- All AI operations work correctly
- Dependencies reduced from 5 to 1

**Dependencies**: None

**Effort**: 3-4 days

**Rationale**: Reduces complexity, maintains full feature parity, better
OpenRouter integration. See AI-STACK-SIMPLIFICATION-OPENROUTER-ONLY-JAN-2026.md
for detailed migration plan.

---

### Phase 1 Validation

**Quality Gates**:

- [x] âœ… Analytics infrastructure (track feature usage)
- [x] âœ… No API keys in client builds (verified)
- [ ] All AI calls routed through serverless functions (not yet implemented)
- [x] âœ… All existing tests passing after SDK migration (747 tests passing)
- [ ] User feedback collection active (not yet implemented)

**Success Metrics**:

- Zero security vulnerabilities
- Analytics coverage > 95% of features
- Build time < 2 minutes

---

## Phase 2: Quick Wins (Weeks 4-9)

### Goal: Ship high-impact, low-risk features while collecting data

#### 2.1 Multi-Modal AI Integration (HIGH Priority, 1 week) âœ… IMPLEMENTED

**Description**: Generate book covers, character portraits, and scene
illustrations using DALL-E 3 and Stable Diffusion XL via OpenRouter.

**Status**: âœ… Implemented and verified

- DALL-E 3 integration complete
  (`src/features/generation/services/imageGenerationService.ts`)
- Book cover generation: Implemented
- Character portrait generation: Implemented
- Scene illustrations: Implemented
- OpenRouter integration: Complete

**Success Criteria**: âœ… All achieved

**Dependencies**: Phase 1.2 (security hardening) - NOT YET IMPLEMENTED

**Effort**: 1 week (completed)

---

#### 2.2 PWA with Offline Support (HIGH Priority, 1 week) âœ… IMPLEMENTED

**Description**: Transform Novelist.ai into a Progressive Web App with offline
capabilities and installability.

**Status**: âœ… Implemented and verified

- Vite PWA plugin integration: Complete
- Service worker for static assets: Generated (`dist/sw.js`)
- PWA assets: Icons and manifest in place
- Installable on mobile/desktop: Yes
- Offline capabilities: Implemented

**Success Criteria**: âœ… All achieved

**Dependencies**: None

**Effort**: 1 week (completed)

---

#### 2.3 Distraction-Free Writing Mode (MEDIUM Priority, 3 days) âœ… IMPLEMENTED

**Description**: Minimal editor UI for focused writing sessions with timer and
word count goals.

**Technical Approach**:

- Toggleable minimal editor UI in `features/editor`
- Focus timer (Pomodoro or custom)
- Word count goals with progress
- Immersive mode (hide all panels)
- Keyboard shortcuts

**Status**: âœ… Implemented and tested

**Implementation Details**:

- Enhanced `FocusMode.tsx` component with full UI
- Pomodoro timer with 15/25/45/60 minute presets
- Word count goals with progress tracking and achievement notifications
- Keyboard shortcuts (ESC to exit, Ctrl+S to save, Ctrl+G for settings)
- Browser notification support
- Comprehensive test coverage (23 tests)

**Success Criteria**: âœ… All achieved

- Focus timer functional with multiple durations
- Word count goals track progress accurately
- Keyboard shortcuts work as expected
- Immersive UI hides all distractions
- Settings panel provides easy configuration

**Dependencies**: Editor feature (available)

**Effort**: 3 days (completed)

---

#### 2.4 Voice Input (Dictation) (LOW Priority, 2-3 days) âœ… IMPLEMENTED

**Description**: Web Speech API integration for voice-based text input.

**Technical Approach**:

- Web Speech API integration
- Browser compatibility layer
- Real-time transcription
- Voice command support (e.g., "save", "new chapter")

**Status**: âœ… Implemented and tested

**Implementation Details**:

- Full Web Speech API integration in `VoiceInputPanel.tsx`
- Real-time transcription with interim and final results
- Voice commands: "save", "new chapter", "undo", "redo", "stop"
- Browser compatibility detection (Chrome, Edge, Safari)
- Error handling for microphone permissions and network issues
- TypeScript type definitions for Speech API
- Comprehensive test coverage (20 tests)

**Success Criteria**: âœ… All achieved

- Voice input works in Chrome/Safari/Edge
- Real-time transcription with interim results display
- Voice commands functional and auto-detected
- Fallback message for unsupported browsers
- Error handling for microphone access denial

**Dependencies**: None

**Effort**: 2-3 days (completed)

**Target Adoption**: >15% of users use this feature

---

### Phase 2 Validation

**Quality Gates**:

- [x] âœ… Multi-Modal AI generates covers/portraits
- [x] âœ… PWA installable and offline writing works
- [x] âœ… Distraction-Free mode functional
- [x] âœ… Voice input works in major browsers
- [x] âœ… All new features have tests passing (747+ tests)

**Success Metrics** (To be measured post-deployment):

- Multi-Modal AI: >30% adoption (target)
- PWA: >50% installs, >20% offline usage (target)
- Distraction-Free: >40% usage, +20% session length (target)
- Voice Input: >15% usage, NPS > 7 (target)

**Phase 2 Status**: âœ… **COMPLETE** - All Quick Wins features implemented and
tested

---

## Phase 3: Context Intelligence (Weeks 10-15)

### Goal: Implement RAG system incrementally based on data

#### 3.1 RAG Phase 1: Project Context Injection (HIGH Priority, 2 weeks)

**Description**: AI becomes context-aware by injecting full project context into
system prompts.

**Technical Approach**:

- Extract project context: characters, world-building, timeline, chapters
- Format context for AI prompts
- Inject context into all AI generation calls
- Token management (avoid exceeding context limits)
- Cache context to avoid regeneration

**Success Criteria**:

- AI suggestions reference characters/world accurately
- Context token usage < 50K tokens per project
- AI acceptance rate increases by 15%

**Dependencies**: Phase 1 (analytics to validate demand)

**Effort**: 2 weeks

**Success Metric**: AI acceptance rate +15%

---

#### 3.2 RAG Phase 2: Semantic Search (MEDIUM Priority, 2 weeks)

**Description**: Generate embeddings for all content and implement semantic
search to find relevant passages.

**Technical Approach**:

- Generate embeddings for all chapters, characters, world entries
- Store embeddings in Turso (JSON column)
- Implement semantic search to find relevant content
- Use search results to enrich AI context
- Cache search results

**Success Criteria**:

- All content has embeddings
- Semantic search returns relevant results
- Search quality metrics meet thresholds (precision > 80%)
- Cost increases acceptable

**Dependencies**: Phase 3.1

**Effort**: 2 weeks

**Success Metric**: Search precision > 80%, AI relevance +10%

---

#### 3.3 RAG Phase 3: Vector Database (LOW Priority, Conditional, 2-3 weeks)

**Description**: Migrate to Pinecone or Weaviate for advanced semantic search
(only if Phase 2 shows insufficient quality).

**Trigger Condition**: Search quality < 75% precision OR > 100K embeddings

**Technical Approach**:

- Evaluate Pinecone vs Weaviate
- Migrate embeddings to vector database
- Update search implementation
- Monitor costs and performance

**Success Criteria**:

- Search precision > 85%
- Query latency < 100ms
- Cost per query acceptable

**Dependencies**: Phase 3.2 + data validation

**Effort**: 2-3 weeks

**Success Metric**: Search precision > 85%

---

#### 3.4 Shared Project Views (MEDIUM Priority, 2 weeks)

**Description**: Generate shareable links for read-only access to projects.

**Technical Approach**:

- Create shareable tokens (UUID) with permissions
- Database schema updates for sharing
- Read-only view UI
- Shareable link generation
- Access control and expiration

**Success Criteria**:

- Users can generate share links
- Read-only view works correctly
- Access control enforced
- Share link usage > 20% of projects

**Dependencies**: None

**Effort**: 2 weeks

**Success Metric**: >20% of projects shared

---

### Phase 3 Validation

**Quality Gates**:

- [ ] AI references context accurately
- [ ] Semantic search returns relevant results
- [ ] Shared views functional and secure
- [ ] All tests passing

**Success Metrics**:

- RAG Phase 1: AI acceptance +15%
- RAG Phase 2: Search precision > 80%
- Shared Views: >20% projects shared

---

## Phase 4: AI Automation (Weeks 16+)

### Goal: Build AI agent framework based on usage patterns

#### 4.1 AI Plot Engine (MEDIUM Priority, 2-3 weeks)

**Description**: Chain existing AI calls for automated plot outlining and
development.

**Technical Approach**:

- Design plot generation workflow
- Chain AI calls: outline â†’ develop â†’ refine
- Interactive plot suggestions
- Timeline integration
- User control over automation level

**Success Criteria**:

- Users can generate complete plots
- Plots integrate with timeline
- User satisfaction > 4/5
- Automation used > 10% of AI interactions

**Dependencies**: RAG Phase 2

**Effort**: 2-3 weeks

**Success Metric**: Automation usage > 10%

---

#### 4.2 AI Agent Framework (MEDIUM Priority, 3-4 weeks)

**Description**: Build simple orchestrator for multi-agent workflows.

**Technical Approach**:

- Simple orchestrator (state machine in Zustand)
- Define agent types: Researcher, Outliner, Writer, Editor
- Agent communication and coordination
- Use OpenRouter SDK for agent operations
- Custom agent workflows using state machine

**Success Criteria**:

- Agents execute defined workflows
- Agent coordination functional
- User can monitor agent progress
- Agent workflows used > 10% of AI calls

**Dependencies**: Phase 4.1

**Effort**: 3-4 weeks

**Success Metric**: Agent workflows > 10%

---

#### 4.3 Real-Time Editing (LOW Priority, Conditional, 4-6 weeks)

**Description**: Implement real-time co-writing with operational transformation
(only if strong demand validated).

**Trigger Condition**: Share link usage > 40% AND comment usage > 30%

**Technical Approach**:

- Yjs library for CRDT-based syncing
- WebSocket server (Cloudflare Durable Objects)
- Conflict resolution
- Presence indicators
- Version history for real-time changes

**Success Criteria**:

- Multiple users can edit simultaneously
- Conflicts resolved correctly
- Presence indicators accurate
- Co-writing sessions > 15% of sessions

**Dependencies**: Strong demand validation from Phase 3

**Effort**: 4-6 weeks

**Success Metric**: Co-writing > 15% of sessions

---

### Phase 4 Validation

**Quality Gates**:

- [ ] AI Plot Engine generates quality plots
- [ ] Agent framework executes workflows
- [ ] Real-time editing (if implemented) works correctly
- [ ] All tests passing

**Success Metrics**:

- AI Plot Engine: Satisfaction > 4/5
- Agent Framework: Workflows > 10% of AI calls
- Real-Time Editing (if built): Co-writing > 15% sessions

---

## Strategic Upgrades (As Needed)

### Vite 8 Upgrade (Rolldown)

**Trigger Condition**: Build time > 3 min OR Vite 8 stable

**Effort**: 1 week

**Benefits**: 10-20% build speed improvement

---

### Slice-Based Zustand

**Trigger Condition**: State management complexity increases

**Effort**: 2 weeks

**Benefits**: Better modularity, easier testing (2025 best practice)

---

### Vector Database Migration

**Trigger Condition**: RAG Phase 2 insufficient quality

**Effort**: 2-3 weeks

**Benefits**: Advanced semantic search

---

## Risk Management

### Risk 1: Low Adoption of New Features

**Mitigation**:

- Phased rollout with A/B testing
- User feedback collection
- Iterate based on data
- Defer complex features if demand low

### Risk 2: AI API Cost Overrun

**Mitigation**:

- Cost tracking per feature
- Alert thresholds ($5/user/month)
- Caching strategies
- Tiered pricing plans

### Risk 3: Technical Debt Accumulation

**Mitigation**:

- Enforce 500 LOC policy
- Min 80% test coverage for new features
- Zero lint warnings
- Code review for architectural compliance

### Risk 4: User Experience Degradation

**Mitigation**:

- Performance monitoring
- A/B testing for UI changes
- Rollback plans
- User feedback channels

---

## Success Metrics

### Feature Adoption Targets

| Feature          | Adoption Target | Failure Threshold |
| ---------------- | --------------- | ----------------- |
| Multi-Modal AI   | >30%            | <10%              |
| PWA              | >50% installs   | <10% installs     |
| Distraction-Free | >40% usage      | <15% usage        |
| Voice Input      | >15% usage      | <5% usage         |
| RAG Phase 1      | AI +15%         | <5% improvement   |
| Shared Views     | >20% shared     | <5% shared        |
| AI Agents        | >10% calls      | <3% calls         |

### Technical Quality Metrics

- **LOC per file**: Max 500
- **Test coverage**: Min 80% for new features
- **Lint warnings**: 0
- **Build time**: <2 min (CI), <5 sec (dev)
- **Bundle size**: <500KB per chunk

### Cost Metrics

- **AI API costs**: Alert at $5/user/month
- **Infrastructure costs**: Alert at $500/month increase
- **Revenue impact**: Aim for $10 LTV increase per feature

---

## Implementation Timeline

### Weeks 1-3: Foundation

- Analytics integration
- Security hardening
- AI SDK v6 upgrade

### Weeks 4-9: Quick Wins

- Multi-Modal AI
- PWA
- Distraction-Free Mode
- Voice Input

### Weeks 10-15: Context Intelligence

- RAG Phase 1-2
- Shared Project Views

### Weeks 16+: AI Automation

- AI Plot Engine
- AI Agent Framework
- Conditional: Real-Time Editing

---

## Monitoring Plan

### Weekly

- Feature adoption rates
- User feedback summaries
- Bug reports by feature
- API cost trends

### Monthly

- User retention by feature cohort
- A/B test results
- Technical debt metrics
- Revenue per user

### Quarterly

- Feature ROI analysis
- User satisfaction surveys
- Competitor feature gap analysis
- Architecture health review

---

## Conclusion

This plan prioritizes shipping user value quickly while building measurement
infrastructure. Strategic investments are made incrementally based on data
validation.

**Key Principles**:

1. Ship value, not architecture (unless critical)
2. Build measurement first, then features
3. Validate demand before investing in complex features
4. Maintain technical excellence (500 LOC, 80% tests)

**Expected Impact**: 3-5x feature richness in 4-5 months with measurable user
value.

**Risk Profile**: LOW - Incremental, validated approach with clear success
metrics.

---

**Plan Generated By**: Analysis-Swarm + GOAP Agent **Status**: 80% Complete
(Phase 1 Foundation + Phase 2 Quick Wins Complete) **Total Timeline**: 4-5
months for core features **Priority**: Strategic Growth

**Last Updated**: January 2, 2026 **Next Phase**: Phase 3 - Context Intelligence
(RAG implementation)
